{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed355d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies for PDF generation\n",
    "!apt-get update -qq\n",
    "!apt-get install -y wkhtmltopdf\n",
    "\n",
    "# Install all Python libraries\n",
    "!pip install -qU crewai crewai_tools langchain-groq sentence-transformers langchain_huggingface \\\n",
    "langchain_openai litellm streamlit pyngrok markdown2 pdfkit matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2108b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import litellm\n",
    "\n",
    "# Setup your API keys (replace with secure input methods for production)\n",
    "os.environ['GROQ_API_KEY'] = ''   # ADD YOUR GROQ API KEY for security reasons\n",
    "os.environ['TAVILY_API_KEY'] = \"\" # ADD YOUR TAVILY API KEY for security reasons\n",
    "\n",
    "# Configure LiteLLM to use Groq\n",
    "litellm.provider = \"groq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358fdebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from langchain_openai import ChatOpenAI\n",
    "from crewai_tools import SerperDevTool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"https://api.groq.com/openai/v1\",\n",
    "    openai_api_key=os.environ['GROQ_API_KEY'],\n",
    "    model_name=\"groq/llama3-8b-8192\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "# Web search tool\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "api_key = os.environ['TAVILY_API_KEY']\n",
    "\n",
    "# Define agents\n",
    "researcher = Agent(\n",
    "    role='Researcher and Specialist Web Scraper',\n",
    "    goal='Search and scrape job platforms like LinkedIn, Bayt, Wuzzuf, and Glassdoor to collect data about the most in-demand AI/ML job roles in MENA.',\n",
    "    backstory='Experienced web scraper focused on job market trends.',\n",
    "    tools=[SerperDevTool(api_key=api_key)],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "data_extraction_agent = Agent(\n",
    "    role='Data Extractor',\n",
    "    goal='Parse job postings to extract job titles, skills, locations, and company names.',\n",
    "    backstory='Data analyst skilled in structured extraction.',\n",
    "    tools=[SerperDevTool(api_key=api_key)],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "trend_analysis_agent = Agent(\n",
    "    role='Trend Analyst',\n",
    "    goal='Analyze job data to identify top roles, skills, and job locations.',\n",
    "    backstory='Market analyst specialized in labor trends.',\n",
    "    tools=[],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "report_writer_agent = Agent(\n",
    "    role='Report Writer',\n",
    "    goal='Compile a structured markdown report with job trends, roles, and visualizations.',\n",
    "    backstory='Technical writer and visual storyteller.',\n",
    "    tools=[],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# Define tasks\n",
    "researcher_task = Task(\n",
    "    description='Scrape LinkedIn, Bayt, Wuzzuf, and Glassdoor for AI/ML jobs in MENA.',\n",
    "    expected_output='Dataset of job titles, skills, locations, and company names.',\n",
    "    agent=researcher\n",
    ")\n",
    "\n",
    "data_extraction_task = Task(\n",
    "    description='Extract structured job data from the scraped postings.',\n",
    "    expected_output='Structured CSV/JSON with job_title, skills, location, company_name.',\n",
    "    agent=data_extraction_agent\n",
    ")\n",
    "\n",
    "trend_analysis_task = Task(\n",
    "    description='Analyze structured data to identify top roles, key skills, and country distribution.',\n",
    "    expected_output='Insight report on AI/ML roles and skills demand by region.',\n",
    "    agent=trend_analysis_agent\n",
    ")\n",
    "\n",
    "report_writer_task = Task(\n",
    "    description='Write markdown report titled \"Top AI/ML Jobs in MENA â€“ May 2025\" with visualizations.',\n",
    "    expected_output='Markdown report with roles, skills, country trends, charts.',\n",
    "    agent=report_writer_agent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew\n",
    "import markdown2\n",
    "import pdfkit\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[researcher, data_extraction_agent, trend_analysis_agent, report_writer_agent],\n",
    "    tasks=[researcher_task, data_extraction_task, trend_analysis_task, report_writer_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Kickoff the crew run\n",
    "result = crew.kickoff()\n",
    "\n",
    "# Preview result snippet\n",
    "print(\"\\n==== Preview: Top AI/ML Roles in MENA ====\")\n",
    "print(result[:1000])\n",
    "\n",
    "# Save as markdown file\n",
    "with open(\"Top_AI_ML_Jobs_MENA_May_2025.md\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(result)\n",
    "\n",
    "# Convert markdown to PDF\n",
    "html = markdown2.markdown(result)\n",
    "pdfkit.from_string(html, \"Top_AI_ML_Jobs_MENA_May_2025.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc1c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def sample_visualization():\n",
    "    roles = ['ML Engineer', 'Data Scientist', 'AI Researcher']\n",
    "    counts = [50, 40, 30]\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.barplot(x=roles, y=counts, palette='viridis')\n",
    "    plt.title('Top AI/ML Roles in MENA')\n",
    "    plt.xlabel('Job Role')\n",
    "    plt.ylabel('Number of Postings')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('roles_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "sample_visualization()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
